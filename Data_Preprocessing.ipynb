{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"data/train.csv\")\n",
    "df['Ticket'] = pd.factorize(df['Ticket'])[0]\n",
    "df['Embarked'] = pd.factorize(df['Embarked'])[0]\n",
    "df_test_result = pd.read_csv(\"data/test.csv\")\n",
    "df_test_result['Ticket'] = pd.factorize(df_test_result['Ticket'])[0]\n",
    "df_test_result['Embarked'] = pd.factorize(df_test_result['Embarked'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 757\n",
      "Test size: 134\n",
      "\n",
      "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Embarked'], dtype='object')\n",
      "           Pclass         Sex         Age       SibSp       Parch      Ticket  \\\n",
      "count  757.000000  757.000000  611.000000  757.000000  757.000000  757.000000   \n",
      "mean     2.301189    0.361955   29.582111    0.536328    0.392338  306.799207   \n",
      "std      0.838341    0.480884   14.601585    1.141017    0.812009  197.560484   \n",
      "min      1.000000    0.000000    0.420000    0.000000    0.000000    0.000000   \n",
      "25%      2.000000    0.000000   20.000000    0.000000    0.000000  132.000000   \n",
      "50%      3.000000    0.000000   28.000000    0.000000    0.000000  286.000000   \n",
      "75%      3.000000    1.000000   38.000000    1.000000    0.000000  473.000000   \n",
      "max      3.000000    1.000000   80.000000    8.000000    6.000000  680.000000   \n",
      "\n",
      "             Fare    Embarked  \n",
      "count  757.000000  757.000000  \n",
      "mean    32.457678    0.361955  \n",
      "std     49.177664    0.637065  \n",
      "min      0.000000   -1.000000  \n",
      "25%      7.925000    0.000000  \n",
      "50%     14.500000    0.000000  \n",
      "75%     31.275000    1.000000  \n",
      "max    512.329200    2.000000  \n"
     ]
    }
   ],
   "source": [
    "y = df[\"Survived\"]\n",
    "X = df.drop([\"Survived\", \"Cabin\", \"Name\", \"PassengerId\"], axis = 1, inplace = False)\n",
    "X['Sex'] = pd.factorize(X['Sex'])[0]\n",
    "\n",
    "df_test_result['Sex'] = pd.factorize(df_test_result['Sex'])[0]\n",
    "df_test_result = df_test_result.drop([\"Cabin\", \"Name\", \"PassengerId\"], axis = 1, inplace = False)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 23, train_size = 0.85)\n",
    "\n",
    "# print(X_train.shape[0], y_train.size, X_test.shape[0], y_test.size)\n",
    "print(\"Train size: {}\\nTest size: {}\\n\".format(X_train.shape[0], X_test.shape[0]) ) \n",
    "\n",
    "print(X_train.columns)\n",
    "print(X_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived_Mean  Not_Survived_Mean  Survived_Std  Not_Survived_Std\n",
      "PassengerId     444.368421         447.016393    252.358840        260.640469\n",
      "Pclass            1.950292           2.531876      0.863321          0.735805\n",
      "Age              28.343690          30.626179     14.950952         14.172110\n",
      "SibSp             0.473684           0.553734      0.708688          1.288399\n",
      "Parch             0.464912           0.329690      0.771712          0.823166\n",
      "Ticket          295.043860         314.220401    183.833314        205.040971\n",
      "Fare             48.395408          22.117887     66.596998         31.388207\n",
      "Embarked          0.441520           0.307832      0.659535          0.620478\n"
     ]
    }
   ],
   "source": [
    "survived = df[ df[\"Survived\"] == 1]\n",
    "n_survived = survived.shape[0]\n",
    "not_survived = df[ df[\"Survived\"] == 0]\n",
    "n_not_survived = not_survived.shape[0]\n",
    "\n",
    "survived_stats = survived.describe()\n",
    "not_survived_stats = not_survived.describe()\n",
    "\n",
    "comparation_stats = pd.DataFrame()\n",
    "comparation_stats[\"Survived_Mean\"] = survived_stats.loc[\"mean\"]\n",
    "comparation_stats[\"Not_Survived_Mean\"] = not_survived_stats.loc[\"mean\"]\n",
    "comparation_stats[\"Survived_Std\"] = survived_stats.loc[\"std\"]\n",
    "comparation_stats[\"Not_Survived_Std\"] = not_survived_stats.loc[\"std\"]\n",
    "comparation_stats = comparation_stats.drop(\"Survived\", inplace = False, axis = 0)\n",
    "print(comparation_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantity of estimated ages: 18\n",
      "Quantity of unique ages: 89\n",
      "\n",
      "           Survived  Not_Survived\n",
      "Age                              \n",
      "[0, 10)    0.111111      0.043716\n",
      "[10, 20)   0.119883      0.111111\n",
      "[20, 30)   0.225146      0.260474\n",
      "[30, 40)   0.213450      0.171220\n",
      "[40, 50)   0.099415      0.100182\n",
      "[50, 60)   0.058480      0.051002\n",
      "[60, 70)   0.017544      0.023679\n",
      "[70, 80)   0.000000      0.010929\n",
      "[80, 90)   0.002924      0.000000\n",
      "[90, 100)  0.000000      0.000000\n"
     ]
    }
   ],
   "source": [
    "age_series = X[\"Age\"]\n",
    "age_series.describe()\n",
    "\n",
    "ascending_ages = age_series.sort_values(ascending = True)\n",
    "unique_ages = pd.unique(age_series)\n",
    "estimated_ages = age_series[age_series%1 == 0.5]\n",
    "n_estimated = estimated_ages.size\n",
    "n_unique = unique_ages.size\n",
    "print(\"Quantity of estimated ages: {}\\nQuantity of unique ages: {}\".format(n_estimated, n_unique) )\n",
    "\n",
    "age_and_survived = df[[\"Age\", \"Survived\"]]\n",
    "age_survived = age_and_survived[ age_and_survived[\"Survived\"]==1 ][\"Age\"]\n",
    "age_not_survived = age_and_survived[ age_and_survived[\"Survived\"]==0 ][\"Age\"]\n",
    "\n",
    "intervals = np.arange(0,101,10)\n",
    "bins_survived = pd.cut(age_survived, intervals, right = False)\n",
    "frequency_survived = bins_survived.value_counts(sort = False) / n_survived\n",
    "\n",
    "bins_not_survived = pd.cut(age_not_survived, intervals, right = False)\n",
    "frequency_not_survived = bins_not_survived.value_counts(sort = False) / n_not_survived\n",
    "\n",
    "comparation_ages = pd.DataFrame()\n",
    "comparation_ages[\"Survived\"] = frequency_survived\n",
    "comparation_ages[\"Not_Survived\"] = frequency_not_survived\n",
    "\n",
    "print()\n",
    "print(comparation_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Age feature\n",
    "\n",
    "X_train = X_train.drop(\"Age\", axis = 1, inplace = False)\n",
    "X_test = X_test.drop(\"Age\", axis = 1, inplace = False)\n",
    "X = X.drop(\"Age\", axis = 1, inplace = False)\n",
    "df_test_result = df_test_result.drop(\"Age\", axis = 1, inplace = False)\n",
    "\n",
    "\n",
    "# Dropping and replacing remaining NaNs\n",
    "\n",
    "X_train = X_train.dropna()\n",
    "y_train = y_train.dropna()\n",
    "X_test = X_test.dropna()\n",
    "y_test = y_test.dropna()\n",
    "\n",
    "mean_values = df_test_result.mean()\n",
    "df_test_result = df_test_result.fillna(mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "y_train = (y_train - y_train.min()) / (y_train.max() - y_train.min())\n",
    "X_test = (X_test - X_test.min()) / (X_test.max() - X_test.min())\n",
    "y_test = (y_test - y_test.min()) / (y_test.max() - y_test.min())\n",
    "df_test_result = (df_test_result - df_test_result.min()) / (df_test_result.max() - df_test_result.min())\n",
    "\n",
    "\n",
    "X_train.to_csv(\"final_data/X_train.csv\", index = False)\n",
    "y_train.to_csv(\"final_data/y_train.csv\", index = False)\n",
    "X_test.to_csv(\"final_data/X_test.csv\", index = False)\n",
    "y_test.to_csv(\"final_data/y_test.csv\", index = False)\n",
    "df_test_result.to_csv(\"final_data/df_test_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
